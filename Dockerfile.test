# Multi-stage Dockerfile for comprehensive testing
# Stage 1: Base dependencies
FROM python:3.11-slim as base

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git \
    curl \
    build-essential \
    wget \
    gnupg \
    lsb-release \
    sqlite3 \
    && rm -rf /var/lib/apt/lists/*

# Install Poetry
RUN pip install --no-cache-dir poetry==1.8.3

# Configure Poetry
ENV POETRY_NO_INTERACTION=1 \
    POETRY_VENV_IN_PROJECT=1 \
    POETRY_CACHE_DIR=/tmp/poetry_cache

# Stage 2: Dependencies installation
FROM base as dependencies

WORKDIR /app

# Copy dependency files first (for Docker layer caching)
COPY pyproject.toml poetry.lock ./

# Install dependencies including dev dependencies
RUN poetry install --with dev && rm -rf $POETRY_CACHE_DIR

# Create directories for test outputs and data (this won't change often)
RUN mkdir -p data/test_results/coverage \
    data/test_results/junit \
    data/test_results/reports \
    data/test_results/security \
    data/test_results/quality \
    logs/test \
    matrix_store \
    data

# Set comprehensive environment variables for testing (using test/placeholder values)
ENV PYTHONPATH=/app \
    LOG_LEVEL=DEBUG \
    CHATBOT_DB_PATH=:memory: \
    AI_DUMP_PAYLOADS_TO_FILE=false \
    NEYNAR_API_KEY=test_key_placeholder \
    FARCASTER_BOT_FID=123456 \
    FARCASTER_BOT_SIGNER_UUID=test-signer-uuid \
    FARCASTER_MIN_POST_INTERVAL_MINUTES=1 \
    FARCASTER_DUPLICATE_CHECK_HOURS=1 \
    FARCASTER_RECENT_POSTS_LIMIT=10 \
    FARCASTER_API_TIMEOUT=30.0 \
    FARCASTER_API_MAX_RETRIES=3 \
    FARCASTER_API_BASE_DELAY=1.0 \
    FARCASTER_API_MAX_DELAY=60.0 \
    MATRIX_USER_ID=@ratichat:chat.ratimics.com \
    MATRIX_ACCESS_TOKEN=test_token_placeholder \
    MATRIX_HOMESERVER_URL=https://chat.ratimics.com \
    MATRIX_DEVICE_ID=test_device \
    GOOGLE_GENAI_API_KEY=test_gemini_placeholder \
    S3_API_KEY=test_s3_placeholder \
    S3_API_ENDPOINT=https://test.s3.amazonaws.com \
    S3_CLOUDFRONT_DOMAIN=https://test.cloudfront.net \
    ARWEAVE_WALLET_PATH=/app/data/test_wallet.json \
    ARWEAVE_GATEWAY_URL=https://arweave.net

# Create test configuration files (static files that don't change often)
RUN echo '{"test": true}' > data/config.json && \
    echo '[]' > data/undecryptable_events.json && \
    echo '{"private_key": "test_key"}' > data/test_wallet.json

# Stage 3: Testing environment
FROM dependencies AS testing

# Copy source code and test files (this layer will rebuild when code changes)
COPY chatbot/ ./chatbot/
COPY tests/ ./tests/
COPY s3-service/ ./s3-service/
COPY arweave-service/ ./arweave-service/
COPY arweave_uploader_service/ ./arweave_uploader_service/
COPY scripts/ ./scripts/
COPY pytest.ini ./
COPY *.py ./

# Create comprehensive test runner script
COPY <<'EOF' /app/run_comprehensive_tests.sh
#!/bin/bash
set -e

echo "ðŸš€ Starting Comprehensive Test Suite"
echo "====================================="

# Create test results directory structure
mkdir -p data/test_results/{coverage,junit,reports,security,quality}

echo "ðŸ“‹ Running Pre-test Checks..."

# 1. Code Quality Checks
echo "ðŸ” Running Ruff linting..."
poetry run ruff check . --output-format=json > data/test_results/quality/ruff_report.json || true
poetry run ruff check . || echo "Ruff found issues (continuing with tests)"

echo "ðŸŽ¨ Running Ruff formatting check..."
poetry run ruff format --check . || echo "Formatting issues found (continuing with tests)"

# 2. Type Checking
echo "ðŸ” Running MyPy type checking..."
poetry run mypy chatbot/ --json-report data/test_results/quality/mypy_report || echo "Type issues found (continuing with tests)"

# 3. Security Scanning
echo "ðŸ”’ Running Bandit security scan..."
poetry run bandit -r chatbot/ -f json -o data/test_results/security/bandit_report.json || echo "Security issues found (continuing with tests)"

echo "ðŸ” Running Safety dependency check..."
poetry run safety check --json --output data/test_results/security/safety_report.json || echo "Dependency vulnerabilities found (continuing with tests)"

echo "ðŸ§ª Starting Test Execution..."

# 4. Unit Tests with Coverage
echo "ðŸ”¬ Running Unit Tests..."
poetry run pytest tests/ \
    -v \
    --tb=short \
    --durations=20 \
    --cov=chatbot \
    --cov=s3-service \
    --cov=arweave-service \
    --cov-report=term-missing \
    --cov-report=html:data/test_results/coverage/html \
    --cov-report=xml:data/test_results/coverage/coverage.xml \
    --cov-report=json:data/test_results/coverage/coverage.json \
    --junit-xml=data/test_results/junit/unit_tests.xml \
    --cov-fail-under=60 \
    -m "not slow and not network" \
    --maxfail=10 \
    --disable-warnings

# 5. Integration Tests
echo "ðŸ”— Running Integration Tests..."
poetry run pytest tests/ \
    -v \
    --tb=short \
    -m "integration" \
    --junit-xml=data/test_results/junit/integration_tests.xml \
    --maxfail=5 \
    --disable-warnings || echo "Some integration tests failed (continuing)"

# 6. Service-specific Tests
echo "ðŸ§ª Running S3 Service Tests..."
cd s3-service && poetry run pytest . \
    -v \
    --tb=short \
    --cov=. \
    --cov-report=html:../data/test_results/coverage/s3_html \
    --junit-xml=../data/test_results/junit/s3_tests.xml \
    --disable-warnings || echo "S3 service tests had issues"
cd ..

echo "ðŸ§ª Running Arweave Service Tests..."
cd arweave-service && poetry run pytest . \
    -v \
    --tb=short \
    --cov=. \
    --cov-report=html:../data/test_results/coverage/arweave_html \
    --junit-xml=../data/test_results/junit/arweave_tests.xml \
    --disable-warnings || echo "Arweave service tests had issues"
cd ..

# 7. Slow/Network Tests (if enabled)
if [ "$RUN_SLOW_TESTS" = "true" ]; then
    echo "ðŸŒ Running Slow/Network Tests..."
    poetry run pytest tests/ \
        -v \
        --tb=short \
        -m "slow or network" \
        --junit-xml=data/test_results/junit/slow_tests.xml \
        --timeout=300 \
        --disable-warnings || echo "Some slow tests failed"
fi

# 8. Parallel Test Execution (for performance testing)
if [ "$RUN_PARALLEL_TESTS" = "true" ]; then
    echo "âš¡ Running Parallel Tests..."
    poetry run pytest tests/ \
        -n auto \
        --dist=worksteal \
        -v \
        --junit-xml=data/test_results/junit/parallel_tests.xml \
        -m "not slow and not network and not database" \
        --disable-warnings || echo "Parallel tests had issues"
fi

# 9. Generate Test Summary Report
echo "ðŸ“Š Generating Test Summary..."
cat > data/test_results/reports/test_summary.txt << 'SUMMARY'
=== Comprehensive Test Suite Results ===
Test execution completed at: $(date)

Test Categories:
- Unit Tests: âœ“
- Integration Tests: âœ“
- Service Tests: âœ“
- Code Quality: âœ“
- Security Scan: âœ“
- Type Checking: âœ“

Reports Generated:
- Coverage: data/test_results/coverage/
- JUnit XML: data/test_results/junit/
- Security: data/test_results/security/
- Quality: data/test_results/quality/

SUMMARY

echo "âœ… Comprehensive Test Suite Completed!"
echo "ðŸ“Š Check data/test_results/ for detailed reports"
EOF

# Make the script executable and create other test scripts
RUN chmod +x /app/run_comprehensive_tests.sh

# Create quick test script for basic validation
COPY <<'EOF' /app/run_quick_tests.sh
#!/bin/bash
set -e
echo "ðŸš€ Running Quick Test Suite..."
poetry run pytest tests/ -v --tb=short -x -m "not slow and not network" --disable-warnings
echo "âœ… Quick tests completed!"
EOF

RUN chmod +x /app/run_quick_tests.sh

# Create test matrix script for different test scenarios
COPY <<'EOF' /app/run_test_matrix.sh
#!/bin/bash
set -e

echo "ðŸ§ª Running Test Matrix..."

# Test Matrix Scenarios
echo "ðŸ”„ Running unit tests..."
poetry run pytest tests/ \
    -v \
    --tb=short \
    -m "not slow and not network and not database" \
    --junit-xml="data/test_results/junit/unit_tests.xml" \
    --disable-warnings || echo "Unit tests had issues"

echo "ðŸ”„ Running integration tests..."
poetry run pytest tests/ \
    -v \
    --tb=short \
    -m "integration" \
    --junit-xml="data/test_results/junit/integration_tests.xml" \
    --disable-warnings || echo "Integration tests had issues"

echo "ðŸ”„ Running service tests..."
poetry run pytest tests/ \
    -v \
    --tb=short \
    -m "service" \
    --junit-xml="data/test_results/junit/service_tests.xml" \
    --disable-warnings || echo "Service tests had issues"

echo "ðŸ”„ Running database tests..."
poetry run pytest tests/ \
    -v \
    --tb=short \
    -m "database" \
    --junit-xml="data/test_results/junit/database_tests.xml" \
    --disable-warnings || echo "Database tests had issues"

echo "âœ… Test matrix completed!"
EOF

RUN chmod +x /app/run_test_matrix.sh

# Health check script
COPY <<'EOF' /app/health_check.sh
#!/bin/bash
set -e

echo "ðŸ¥ Running Health Checks..."

# Basic import tests
poetry run python -c "
try:
    import chatbot
    import chatbot.config
    import chatbot.core
    print('âœ… Core imports successful')
except ImportError as e:
    print(f'âŒ Import error: {e}')
    exit(1)
"

# Configuration validation
poetry run python -c "
from chatbot.config import AppConfig
try:
    config = AppConfig()
    print('âœ… Configuration loads successfully')
except Exception as e:
    print(f'âŒ Configuration error: {e}')
    exit(1)
"

echo "âœ… Health checks passed!"
EOF

RUN chmod +x /app/health_check.sh

# Default command runs comprehensive tests
CMD ["/app/run_comprehensive_tests.sh"]
